{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Detection using Image Classification and Object Detection\n",
    " Two different model architectures would be used to train the custom model. For image classification and object detection, respectively, \n",
    " the **EfficientNet** and **YOLO** models were chosen for their reliability and fast inference times, effective for real-time processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- COCO 2017 https://cocodataset.org/ \n",
    "- Traffic-Netv1 https://github.com/OlafenwaMoses/Traffic-Net/releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing COCO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/Users/bualoydgreat/fiftyone/coco-2017/train' if necessary\n",
      "Downloading annotations to '/Users/bualoydgreat/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
      " 100% |██████|    1.9Gb/1.9Gb [1.6m elapsed, 0s remaining, 26.3Mb/s]        \n",
      "Extracting annotations to '/Users/bualoydgreat/fiftyone/coco-2017/raw/instances_train2017.json'\n",
      "Downloading 5000 images\n",
      " 100% |████████████████| 5000/5000 [18.0m elapsed, 0s remaining, 2.9 images/s]      \n",
      "Writing annotations for 5000 downloaded samples to '/Users/bualoydgreat/fiftyone/coco-2017/train/labels.json'\n",
      "Downloading split 'validation' to '/Users/bualoydgreat/fiftyone/coco-2017/validation' if necessary\n",
      "Found annotations at '/Users/bualoydgreat/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Only found 2968 (<5000) samples matching your requirements\n",
      "Downloading 2968 images\n",
      " 100% |████████████████| 2968/2968 [11.0m elapsed, 0s remaining, 3.0 images/s]      \n",
      "Writing annotations for 2968 downloaded samples to '/Users/bualoydgreat/fiftyone/coco-2017/validation/labels.json'\n",
      "Dataset info written to '/Users/bualoydgreat/fiftyone/coco-2017/info.json'\n",
      "Loading 'coco-2017' split 'train'\n",
      " 100% |███████████████| 5000/5000 [9.2s elapsed, 0s remaining, 546.0 samples/s]       \n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |███████████████| 2968/2968 [5.6s elapsed, 0s remaining, 545.7 samples/s]      \n",
      "Dataset 'coco-2017-train-validation-5000' created\n"
     ]
    }
   ],
   "source": [
    "# Define the classes and maximum samples per class\n",
    "classes = [\"person\", \"bicycle\", \"motorcycle\", \"bus\", \"truck\", \"car\"]\n",
    "\n",
    "# Load COCO dataset with annotations filtered for classes\n",
    "detection_dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    splits=[\"train\",\"validation\"],\n",
    "    label_types=[\"detections\"],\n",
    "    classes=classes,\n",
    "    include_id=False,\n",
    "    include_license=False,\n",
    "    only_matching=True,\n",
    "    seed=12,\n",
    "    max_samples=5000, \n",
    "    progress=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(detection_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 5000/5000 [8.0s elapsed, 0s remaining, 687.3 samples/s]       \n",
      "Directory '/Users/bualoydgreat/PERSONAL-TEMPS/optimized-traffic-light-computer-vision/dataset/yolo' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 2968/2968 [4.4s elapsed, 0s remaining, 716.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Export the filtered dataset to COCO format\n",
    "export_dir = \"/Users/bualoydgreat/PERSONAL-TEMPS/optimized-traffic-light-computer-vision/dataset/yolo\"\n",
    "\n",
    "# The splits to export\n",
    "splits = [\"train\", \"validation\"]\n",
    "\n",
    "# Export the splits\n",
    "for split in splits:\n",
    "    split_view = detection_dataset.match_tags(split)\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=\"detections\",\n",
    "        split=split,\n",
    "        classes=classes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 100/100 [1.8s elapsed, 0s remaining, 56.5 samples/s]      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=28a194fc-b582-4569-adda-d7f745a39820\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15bb1a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The directory containing the dataset to import\n",
    "dataset_dir = \"/Users/bualoydgreat/PERSONAL-TEMPS/optimized-traffic-light-computer-vision/dataset/coco\"\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.COCODetectionDataset # for example\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=dataset_type,\n",
    "    name=\"screenshot_100\",\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████████| 99/99 [1.0s elapsed, 0s remaining, 94.3 samples/s]          \n",
      " 100% |█████████████████████| 0/0 [1.4ms elapsed, ? remaining, ? samples/s] \n"
     ]
    }
   ],
   "source": [
    "import fiftyone.utils.random as four\n",
    "\n",
    "four.random_split(dataset, {\"train\": 0.85, \"val\": 0.15})\n",
    "train_view = dataset.match_tags(\"train\")\n",
    "val_view = dataset.match_tags(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m export_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/bualoydgreat/PERSONAL-TEMPS/optimized-traffic-light-computer-vision/dataset/custom-100\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Export the splits\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[43msplits\u001b[49m:\n\u001b[1;32m      6\u001b[0m     split_view \u001b[38;5;241m=\u001b[39m detection_dataset\u001b[38;5;241m.\u001b[39mmatch_tags(split)\n\u001b[1;32m      7\u001b[0m     split_view\u001b[38;5;241m.\u001b[39mexport(\n\u001b[1;32m      8\u001b[0m         export_dir\u001b[38;5;241m=\u001b[39mexport_dir,\n\u001b[1;32m      9\u001b[0m         dataset_type\u001b[38;5;241m=\u001b[39mfo\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mYOLOv5Dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m     13\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'splits' is not defined"
     ]
    }
   ],
   "source": [
    "# Export the filtered dataset to COCO format\n",
    "export_dir = \"/Users/bualoydgreat/PERSONAL-TEMPS/optimized-traffic-light-computer-vision/dataset/custom-100\"\n",
    "\n",
    "\n",
    "split_view = detection_dataset.match_tags(split)\n",
    "split_view.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    label_field=\"detections\",\n",
    "    split=\"train\",\n",
    "    classes=classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Traffic-Net v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L https://github.com/OlafenwaMoses/Traffic-Net/releases/download/1.0/trafficnet_dataset_v1.zip > trafficnet.zip\n",
    "!unzip trafficnet.zip\n",
    "#!sudo rm trafficnet.zip\n",
    "#!sudo mv trafficnet_dataset_v1 /dataset/trafficnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection\n",
    "Using Ultralytics YOLOv8 to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model using M1/M2\n",
    "results = model.train(data='dataset.yaml', epochs=100, imgsz=640, device='mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might not need to train the Object Detection model since YOLOv8 is already trained using the COCO dataset. We just need the right classes to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "model.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes we need from the COCO dataset are the following:\n",
    "```txt\n",
    "0: 'person'\n",
    "1: 'bicycle'\n",
    "2: 'car'\n",
    "3: 'motorcycle'\n",
    "5: 'bus'\n",
    "7: 'truck',\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.predict(source=\"0\", show=True, stream=True, classes=[0])\n",
    "for i, (result) in enumerate(results):\n",
    "    print('Do something with classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "Using Traffic-Net V1 dataset to train the an image classification model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimized-traffic-light-computer-vision-qFVulMxY",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
